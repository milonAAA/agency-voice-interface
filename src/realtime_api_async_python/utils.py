# src/realtime_api_async_python/utils.py
import base64
import json
import logging
import os
from datetime import datetime
from pydantic import BaseModel
import openai
from realtime_api_async_python.config import RUN_TIME_TABLE_LOG_JSON


def base64_encode_audio(audio_bytes: bytes) -> str:
    return base64.b64encode(audio_bytes).decode("utf-8")


def log_runtime(function_or_name: str, duration: float):
    time_record = {
        "timestamp": datetime.now().isoformat(),
        "function": function_or_name,
        "duration": f"{duration:.4f}",
    }
    with open(RUN_TIME_TABLE_LOG_JSON, "a") as file:
        json.dump(time_record, file)
        file.write("\n")

    logging.info(f"â° {function_or_name}() took {duration:.4f} seconds")


def log_ws_event(direction: str, event: dict):
    event_type = event.get("type", "Unknown")
    event_emojis = {
        "session.update": "ðŸ› ï¸",
        "session.created": "ðŸ”Œ",
        "session.updated": "ðŸ”„",
        "input_audio_buffer.append": "ðŸŽ¤",
        "input_audio_buffer.commit": "âœ…",
        "input_audio_buffer.speech_started": "ðŸ—£ï¸",
        "input_audio_buffer.speech_stopped": "ðŸ¤«",
        "input_audio_buffer.cleared": "ðŸ§¹",
        "input_audio_buffer.committed": "ðŸ“¨",
        "conversation.item.create": "ðŸ“¥",
        "conversation.item.delete": "ðŸ—‘ï¸",
        "conversation.item.truncate": "âœ‚ï¸",
        "conversation.item.created": "ðŸ“¤",
        "conversation.item.deleted": "ðŸ—‘ï¸",
        "conversation.item.truncated": "âœ‚ï¸",
        "response.create": "âž¡ï¸",
        "response.created": "ðŸ“",
        "response.output_item.added": "âž•",
        "response.output_item.done": "âœ…",
        "response.text.delta": "âœï¸",
        "response.text.done": "ðŸ“",
        "response.audio.delta": "ðŸ”Š",
        "response.audio.done": "ðŸ”‡",
        "response.done": "âœ”ï¸",
        "response.cancel": "â›”",
        "response.function_call_arguments.delta": "ðŸ“¥",
        "response.function_call_arguments.done": "ðŸ“¥",
        "rate_limits.updated": "â³",
        "error": "âŒ",
        "conversation.item.input_audio_transcription.completed": "ðŸ“",
        "conversation.item.input_audio_transcription.failed": "âš ï¸",
    }
    emoji = event_emojis.get(event_type, "â“")
    icon = "â¬†ï¸ - Out" if direction.lower() == "outgoing" else "â¬‡ï¸ - In"
    logging.info(f"{emoji} {icon} {event_type}")


def structured_output_prompt(prompt: str, response_format: BaseModel) -> BaseModel:
    client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    completion = client.beta.chat.completions.parse(
        model="gpt-4o-2024-08-06",
        messages=[{"role": "user", "content": prompt}],
        response_format=response_format,
    )
    message = completion.choices[0].message
    if not message.parsed:
        raise ValueError(message.refusal)
    return message.parsed


def chat_prompt(prompt: str, model: str) -> str:
    client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    completion = client.beta.chat.completions.parse(
        model=model,
        messages=[{"role": "user", "content": prompt}],
    )
    return completion.choices[0].message.content
